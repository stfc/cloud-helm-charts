
openstack-cluster:
  # The name of the cloud to use from the specified clouds.yaml
  cloudName: openstack

  cloudCredentialsSecretName: cloud-credentials
  # The Kubernetes version of the cluster
  # This should match the version of kubelet and kubeadm in the image
  # and will be automatically updated by us
  # we aim to keep n-1 of latest K8s version
  kubernetesVersion: "1.32.4"
  # The name of the image to use for cluster machines
  machineImage: "capi-ubuntu-2204-kube-v1.32.4-2025-05-02"

  # Values for the Kubernetes cluster network
  kubeNetwork:
    # By default, use the private network range 10.0.0.0/12 for the cluster network
    # We split it into two equally-sized blocks for pods and services
    # This gives ~500,000 addresses in each block and distinguishes it from
    # internal net on 172.16.x.y
    pods:
      cidrBlocks:
        - 10.0.0.0/13
    services:
      cidrBlocks:
        - 10.8.0.0/13
    serviceDomain: cluster.local

  clusterNetworking:
    internalNetwork: 
      nodeCidr: 192.168.128.0/17

  # Settings for registry mirrors
  registryMirrors: { docker.io: ["https://dockerhub.stfc.ac.uk"] }

  # Settings for the Kubernetes API server
  apiServer:
    # Indicates whether to deploy a load balancer for the API server
    enableLoadBalancer: true
    # Indicates whether to associate a floating IP with the API server
    associateFloatingIP: true
    # The port to use for the API server
    port: 6443

  controlPlane:
    # The number of control plane machines to deploy
    # For high-availability, this should be greater than 1
    # For etcd quorum, it should be odd - usually 3, or 5 for very large clusters
    machineCount: 5
    # The flavor to use for control plane machines
    machineFlavor: l3.nano

    # chart defaults cause OutofSync issues in argocd as it doesn't include "0m0s"
    remediationStrategy:
      retryPeriod: 20m0s
      minHealthyPeriod: 1h0m0s

  # Defaults for node groups
  nodeGroupDefaults:
    # Indicates if the node group should be autoscaled
    autoscale: false
    # The flavor to use for machines in the node group
    machineFlavor: l3.micro

    rolloutStrategy:
      type: RollingUpdate
      rollingUpdate:
        # The maximum number of node group machines that can be unavailable during the update
        # Can be an absolute number or a percentage of the desired count
        maxUnavailable: 0
        # The maximum number of machines that can be scheduled above the desired count for
        # the group during an update
        # Can be an absolute number or a percentage of the desired count
        maxSurge: 1
        # One of Random, Newest, Oldest
        deletePolicy: Random

    healthCheck:
      # Indicates if the machine health check should be enabled
      enabled: true
      # The spec for the health check
      spec:
        # By default, 20% unhealthy worker nodes remediated at a time
        # https://cluster-api.sigs.k8s.io/tasks/automated-machine-management/healthchecking#max-unhealthy
        maxUnhealthy: 20%
        # If a node takes longer than 10 mins to startup, remediate it
        nodeStartupTimeout: 10m0s
        # By default, consider a worker node that has not been Ready for
        # more than 5 mins unhealthy
        unhealthyConditions:
          - type: Ready
            status: Unknown
            timeout: 10m0s
          - type: Ready
            status: "False"
            timeout: 10m0s

  addons:
    # Enable monitoring by default, this deploys
    # https://github.com/stackhpc/capi-helm-charts/blob/main/charts/cluster-addons/README.md#monitoring-and-logging
    # and includes Loki which is required for central logging as per UKRI policy
    monitoring:
      enabled: true
      # disable loki-stack by default 
      # we'll setup our own log collection
      lokiStack:
        enabled: false
    # set availabilty zone as upstream uses nova by default
    openstack:
      csiCinder:
        defaultStorageClass:
          availabilityZone: ceph